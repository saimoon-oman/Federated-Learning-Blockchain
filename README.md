# Federated Learning using Blockchain

### Introduction
The training of machine learning (ML) models necessitates access to vast amounts of data, yet centralized data storage poses efficiency and privacy challenges. Federated learning (FL) circumvents these issues by sharing model weights instead of raw data; however, it remains vulnerable to single-point failures. To address this, we propose integrating blockchain technology. Furthermore, to safeguard individual privacy, we incorporate differential privacy measures. This paper introduces a trust-based framework that selectively computes trust scores for nodes, prioritizing lower-ranked nodes while imposing penalties on higher-ranked ones. This approach not only achieves comparable results to existing approaches but also significantly reduces computation time, presenting an optimized and lightweight solution for collaborative ML training.

### Objectives
<ul>
  <li>Integrate blockchain and differential privacy techniques to establish an optimized  decentralized framework for distributed training.</li>
  <li>Ensures data remains at its source, enhancing privacy and security.</li>
  <li>Provides decentralization, traceability, and secure model storage. Prevents malicious alterations to the global model.</li>
  <li>Protects data holder identities through plausible deniability, enhancing privacy.</li>
</ul>
